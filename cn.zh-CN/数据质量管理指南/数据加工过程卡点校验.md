# 数据加工过程卡点校验 {#concept_185254 .concept}

在线系统数据加工过程卡点校验，主要是指在业务系统的数据生成过程中进行的卡点校验。

## 在线系统卡点校验 {#section_nbp_401_fl0 .section}

在线业务系统产生的数据是数据仓库的数据来源之一。在线业务系统复杂多变，每次变更都会产生数据的变化，因此，数仓需要适应多变的业务发展，及时保障数据的准确性。此外，如何能将在线业务的变更高效地通知给基于MaxCompute的离线数仓，也是需要考虑的问题。

建议您同时注重工具和人员管理：既要在工具上自动捕捉每一次业务的变化，也要求开发人员下意识地进行业务变更通知。

-   注重发布平台

    在业务进行重大变更时，订阅这个发布过程，通知离线开发人员，使其知晓此次变更内容。当业务系统足够繁杂，日常发布变更频繁的情况下，若每次变更都通知离线业务，会造成不必要的时间浪费，也影响业务迭代效率。

    此时，可以通过使用数据资产等级的标识对业务进行打标。针对高等级的数据资产，整理出何种类型的变更会影响数据的加工。例如对于相关财务报表而言，如果业务系统的改造影响财务报表的计算，导致约定好的计算口径被业务系统发布变更修改，那么这种情况必须告知离线业务，离线开发人员也必须主动关注这类发布变更通知。

    **说明：** 发布平台不是指阿里云提供发布平台，只是一种统称，是各个企业自己在线业务的相关发布平台。

-   注重数据库的变化感知

    随着业务的发展，业务数据库（MaxCompute数仓的数据源）会出现数据库扩容或者DDL变更，这些变更都要主动通知到离线开发人员。基于MaxCompute的数据仓库在进行离线数据抽取时，通过DataWorks的数据集成工具，可能会限制某个业务数据库表。如果该数据库表发生扩容或者迁移等，数据集成工具感知不到，可能导致数据抽取错漏，而一旦错漏，会影响下游所有依赖该表的应用，因此建议业务数据库也需要有库表变更通知。

-   注重操作工具的人员

    操作工具只是一种辅助手段，操作工具的人员才是核心。数据资产等级的上下游打通的过程需要通知给在线开发人员，使其知晓哪些是重要的核心数据资产，提高在线开发人员的数据风险意识。通过培训等方式将离线数据的诉求、离线数据的加工过程、数据产品的应用方式告诉在线业务开发人员，让其了解数据的重要性，了解数据的价值，同时也告知出错的后果。确保在线开发人员在完成业务目标时，也要考虑数据的目标，做到业务端和数据端一致。


## 离线系统卡点校验 {#section_f9z_vqu_wum .section}

MaxCompute进行数据加工的基本流程为：数据从业务系统上产生，通过同步工具（DataWorks的数据集成或阿里云DTS）进入数仓系统（MaxCompute），数据在数仓中进行清洗、加工、整合、算法、模型等一系列运算后，再通过同步工具输出到数据产品中进行消费。整个流程中，有了数据加工，才有了数据仓库模型和数据仓库代码的建设，如何保障数据加工过程中的质量是离线数据仓库保障数据质量的一个重要环节。

MaxCompute进行数据加工，可以通过DataWorks、MaxCompute studio、MaxCompute SDK提交各种任务进行加工。无论用什么工具，都会经历代码开发到测试、发布到运维、变更的过程。您可以对这个过程中的每个环节进行卡点校验。

-   代码提交的卡点校验

    即在SQL提交前进行相关规则校验。目前公共云没有直接可用的工具辅助校验，有能力的用户可以自己开发相关的工具。规则分类如下：

    -   代码规范类规则，如表命名规范、生命周期设置、表注释等。
    -   代码质量类规则，如分母为0提醒、NULL值参与计算影响结果提醒、插入字段顺序错误等。
    -   代码性能类规则，如分区裁剪失效、扫描大表提醒、重复计算检测等。
-   任务发布上线时的卡点校验

    为保障线上数据的准确性，每次变更都需要经过测试再发布到线上生产环境，且生产环境测试通过后才算发布成功。

-   任务变更或数据重跑

    在进行更新操作前，需要通知下游变更原因、变更逻辑、变更时间等信息，下游对此次变更没有异议后再按照约定时间执行发布变更，这样可以将变更对下游的影响降到最低。


