# 作业诊断 {#concept_263782 .concept}

提交作业后，您需要根据作业日志来检查作业是否已正常提交并执行。MaxCompute为Spark作业提供了Logview工具以及Spark Web-UI，帮助开发者进行作业诊断。

例如通过Spark-submit方式（Dataworks执行Spark任务时也会产生相应日志）提交作业，在作业日志中会打印以下关键内容。

``` {#codeblock_i6a_0eu_ey4}
cd $SPARK_HOME
bin/spark-submit --master yarn-cluster --class  SparkPi /tmp/spark-2.x-demo/target/AliSpark-2.x-quickstart-1.0-SNAPSHOT-shaded.jar
作业提交成功后，MaxCompute会创建一个instance，在日志中会打印instance的logview:
19/01/05 20:36:47 INFO YarnClientImplUtil: logview url: http://logview.odps.aliyun.com/logview/?h=http://service.cn.maxcompute.aliyun.com/api&p=qn_beijing&i=20190105123647703gpqn26pr2&token=eG94TG1iTkZDSFErc1ZPcUZyTTdSWWQ3UE44PSxPRFBTX09CTzoxODc1NjUzNjIyNTQzMDYxLDE1NDY5NTEwMDcseyJTdGF0ZW1lbnQiOlt7IkFjdGlvbiI6WyJvZHBzOlJlYWQiXSwiRWZmZWN0IjoiQWxsb3ciLCJSZXNvdXJjZSI6WyJhY3M6b2RwczoqOnByb2plY3RzL3FuX2JlaWppbmcvaW5zdGFuY2VzLzIwMTkwMTA1MTIzNjQ3NzAzZ3BxbjI2cHIyIl19XSwiVmVyc2lvbiI6IjEifQ==
成功标准: <看到以下输出，可能会有其他日志一并输出>
19/01/05 20:37:34 INFO Client:
   client token: N/A
   diagnostics: N/A
   ApplicationMaster host: 11.220.203.36
   ApplicationMaster RPC port: 30002
   queue: queue
   start time: 1546691807945
   final status: SUCCEEDED
   tracking URL: http://jobview.odps.aliyun.com/proxyview/jobview/?h=http://service.cn.maxcompute.aliyun-inc.com/api&p=project_name&i=20190105123647703gpqn26pr2&t=spark&id=application_1546691794888_113905562&metaname=20190105123647703gpqn26pr2&token=TjhlQWswZTRpYWN2L3RuK25VeE5LVy9xSUNjPSxPRFBTX09CTzoxODc1NjUzNjIyNTQzMDYxLDE1NDY5NTEwMzcseyJTdGF0ZW1lbnQiOlt7IkFjdGlvbiI6WyJvZHBzOlJlYWQiXSwiRWZmZWN0IjoiQWxsb3ciLCJSZXNvdXJjZSI6WyJhY3M6b2RwczoqOnByb2plY3RzL3FuX2JlaWppbmcvaW5zdGFuY2VzLzIwMTkwMTA1MTIzNjQ3NzAzZ3BxbjI2cHIyIl19XSwiVmVyc2lvbiI6IjEifQ==
```

## 使用Logview工具诊断作业 {#section_1jp_5nc_ofs .section}

1.  通过日志输出的logview，在浏览器中可以查看CUPID类型的任务执行的基本信息。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/217830/155771138247096_zh-CN.jpg)

2.  单击**TaskName**下名为master-0的任务条，在下方**FuxiInstance**栏中，通过**All**过滤。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/217830/155771138247097_zh-CN.jpg)

3.  单击TempRoot的**StdOut**，可以查看SparkPi的输出结果。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/217830/155771138247098_zh-CN.jpg)


## 使用Web-UI诊断作业 {#section_e1m_v1q_tv6 .section}

日志中打印出上述的TrackingUrl，表示您的作业已经提交到MaxCompute集群。这个TrackingUrl非常关键，它既是SparkWebUI，也是HistoryServer的url。

1.  在浏览器中打开这个url，可以追踪Spark作业的运行情况。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/217830/155771138347099_zh-CN.jpg)

2.  单击driver的**stdout**即可以查看Spark作业的输出内容。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/217830/155771138347100_zh-CN.jpg)


