# 常见问题 {#concept_y5c_w5c_kgb .concept}

本小节总结Spark使用过程中的常见问题。

-   Q：spark-defaults.conf提供的id、key有问题，提示：

    ```language-java
    Stack:
    com.aliyun.odps.OdpsException: ODPS-0410042:
    Invalid signature value - User signature dose not match
    ```

    A：请检查spark-defaults.conf提供的id、key和在阿里云官网管理控制台[用户信息管理](https://account.aliyun.com/login/login.htm?oauth_callback=https://usercenter.console.aliyun.com/)中的AccessKey ID、Access Key Secret是否一致。

-   Q：提示权限不足

    ```language-java
    Stack:
    com.aliyun.odps.OdpsException: ODPS-0420095: 
    Access Denied - Authorization Failed [4019], You have NO privilege 'odps:CreateResource' on {acs:odps:*:projects/*}
    ```

    A：请project owner授权grant resource的read以及create权限。

-   Q：项目未支持Spark任务运行，提示：

    ```language-java
    Exception in thread "main" org.apache.hadoop.yarn.exceptions.YarnException: com.aliyun.odps.OdpsException: ODPS-0420095: Access Denied - The task is not in release range: CUPID
    ```

    A：首先需要确认项目所在的region中，是否已经提供了MaxCompute Spark服务。同时，如果region已经支持，请通过工单或加入钉钉群：21969532（MaxCompute Spark支持群）进行咨询。

-   Q：如何通过Spark访问VPC环境内服务？

    A：Spark默认支持对MaxCompute表的访问，支持对OSS、OTS等外部数据源的访问处理。对VPC内的服务访问，目前默认暂不支持访问，如有需求可以通过工单和我们联系。

-   Q：如何把开源Spark代码迁移到Spark on MaxCompute？

    A：分以下三种情况：

    -   作业无需访问MaxCompute表和OSS

        用户jar包可直接运行，参照第二节准备开发环境和修改配置。注意，对于spark或hadoop的依赖必须设成provided。

    -   作业需要访问MaxCompute表

        配置相关依赖后重新打包即可。配置依赖的步骤请参见[配置依赖](cn.zh-CN/用户指南/Spark/搭建开发环境.md#section_oey_mqy_cq1)。

    -   作业需要访问OSS

        配置相关依赖后重新打包即可。配置依赖的步骤请参见[配置依赖](cn.zh-CN/用户指南/Spark/搭建开发环境.md#section_oey_mqy_cq1)。


