# 公告

本文为您提供关于MaxCompute使用功能的各项更新记录。

## 2020年10月13日-SQL兼容性升级

SQL兼容性升级时间预计如下，如有变更，请以实际通知时间为准。

|批次|站点|升级时间|
|--|--|----|
|第一批|印度（孟买）、印度尼西亚（雅加达） 、英国（伦敦）|10月13日|
|第二批|美国（弗吉尼亚）、阿联酋（迪拜）、华北2政务云（北京）、华东2金融云（上海）|10月15日|
|第三批|日本（东京）、澳大利亚（悉尼）、美国（硅谷）、马来西亚（吉隆坡）|10月20日|
|第四批|新加坡（新加坡）、中国（香港）、德国（法兰克福）|10月22日|

MaxCompute SQL中的`URL_DECODE`和`CONV`函数升级，详细变更如下：

-   `URL_DECODE`函数
    -   升级前：如果`URL_DECODE`函数存在两个参数，第二个编码参数不生效，系统按照UTF-8编码格式解码，即`URL_DECODE(url, "gbk")`等于`URL_DECODE(url)`。
    -   升级后：如果`URL_DECODE`函数存在两个参数，系统首先按照百分号（%）解码，然后按照第二个编码参数的编码格式解码，返回结果字符串。在DataWorks数据开发环境运行命令的示例如下。

        ```
        SELECT URL_DECODE("%CD%F5", "gbk");
        -- 升级前返回乱码。填写的编码参数GBK不生效，使用UTF-8编码格式解码。
        -- 升级后返回“王”。\xCD\xF5是“王”的GBK编码。
        
        SELECT URL_DECODE("%E7%8E%8B", "gbk");
        -- 升级前返回“王”。%E7%8E%8B是“王”的UTF-8编码。填写的编码参数GBK不生效，仍然使用UTF-8编码格式解码。
        -- 升级后返回NULL。\xE7\x8E\x8B不是合法的GBK编码。
        
        SELECT URL_DECODE("%E7%8E%8B");
        -- 升级前后都返回“王”。%E7%8E%8B是“王”的UTF-8编码。不填写编码参数，默认使用UTF-8编码格式解码。
        ```

        **说明：** 在Windows环境下通过MaxCompute客户端（odpscmd）执行命令时，由于Windows环境存在`cmd`编码转换问题，可能会将GBK编码再次转换为其他编码。

-   `CONV`函数
    -   如果项目空间为Hive兼容模式版本，对于非法输入参数，升级前后都返回0。
    -   如果项目空间为1.0或2.0数据类型版本：
        -   升级前：如果查询的表字段为非法参数，返回结果为乱码。
        -   升级后：如果查询的表字段为非法参数，返回结果为NULL。

            例如，`CONV("00e04c9d034a", 2, 10)`返回结果为NULL。


## 2020年7月24日-MaxCompute新增聚合函数

MaxCompute新增聚合函数`APPROX_DISTINCT(value)`、`ANY_VALUE(value)`、`ARG_MAX(valueToMaximize, valueToReturn)`和`ARG_MIN(valueToMinimize, valueToReturn)`。函数功能如下：

-   `APPROX_DISTINCT(value)`：返回输入的非重复值的近似数目。
-   `ANY_VALUE(value)`：返回取值范围内的任意一个值。
-   `ARG_MAX(valueToMaximize, valueToReturn)`：返回valueToMaximize最大值对应行的valueToReturn。
-   `ARG_MIN(valueToMinimize, valueToReturn)`：返回valueToMinimize最小值对应行的valueToReturn。

新增聚合函数详情请参见[聚合函数](/intl.zh-CN/开发/SQL及函数/内建函数/聚合函数.md)。

## 2020年7月29日-新增项目的默认数据类型版本从1.0变更为2.0

MaxCompute通过DataWorks控制台新增项目时，项目的默认数据类型版本从1.0变更为2.0。该变更将于2020年7月29日到2020年8月6日陆续对国际站各个区域进行升级。如果您之前创建过存量项目，新建项目时需要选择合适的数据类型版本。不同数据类型版本的项目进行数据交互时可能会引起兼容性问题。

MaxCompute有3个数据类型版本，不同数据类型版本在定义和行为上有一定的差异。MaxCompute将数据类型相关属性组成3个组合，分别对应1.0数据类型版本、2.0数据类型版本和Hive兼容数据类型版本。详情请参见[数据类型版本说明](/intl.zh-CN/开发/数据类型/数据类型版本说明.md)。

**说明：** 此功能对存量项目的数据类型版本无影响。如果存量项目需要更新数据类型版本，请参见[修改项目的数据类型版本](/intl.zh-CN/开发/数据类型/数据类型版本说明.mdsection_t3g_38q_0ix)。

## 2020年6月29日-新增项目支持选择数据类型版本功能上线

MaxCompute新增项目初始化数据类型版本的功能将于2020年6月29日到2020年7月15日陆续对国际站各个区域进行升级。升级完成后，您在创建新项目时，将需要选择初始化数据类型版本。

MaxCompute有3个数据类型版本，不同数据类型版本在定义和行为上有一定的差异。MaxCompute将数据类型相关属性组成3个组合，分别对应1.0数据类型版本、2.0数据类型版本和Hive兼容数据类型版本。详情请参见[数据类型版本说明](/intl.zh-CN/开发/数据类型/数据类型版本说明.md)。

**说明：** 此功能对存量项目的数据类型版本无影响。如果存量项目需要更新数据类型版本，请参见[修改项目的数据类型版本](/intl.zh-CN/开发/数据类型/数据类型版本说明.mdsection_t3g_38q_0ix)。

## 2020年3月15日-MaxCompute存储降价

MaxCompute于2020年3月15日开始，对现有的[存储费用（按量计费）](/intl.zh-CN/产品定价/存储费用（按量计费）.md)进行降价，降价原则：

-   将原来的5个阶梯价调成3个阶梯价，减少存储计费复杂度。
-   将新阶梯单价调低，最终达到降价目的。

2020年3月15日前，原存储阶梯价如下。

|存储量|阶梯单价|固定价|
|---|----|---|
|大于0 GB小于等于1 GB|不涉及|0.00元/天|
|大于1 GB小于等于100 GB|0.0028 USD/GB/天|不涉及|
|大于100 GB小于等于1 TB|0.0014 USD/GB/天|不涉及|
|大于1 TB小于等于10 TB|0.0013 USD/GB/天|不涉及|
|大于10 TB小于等于100 TB|0.0011 USD/GB/天|不涉及|
|大于100 TB|0.0009 USD/GB/天|不涉及|

2020年3月15日起，新存储阶梯价如下。

|存储量|阶梯单价|固定价|
|---|----|---|
|大于0 GB小于等于1 GB|不涉及|0.00 USD/天|
|大于1 GB小于等于10 TB|0.0011 USD/GB/天|不涉及|
|大于10TB小于等于100 TB|0.0009 USD/GB/天|不涉及|
|大于100 TB|0.0006 USD/GB/天|不涉及|

存储计费统计方式不变，更多信息请参见[存储费用（按量计费）](/intl.zh-CN/产品定价/存储费用（按量计费）.md)：

-   存储到MaxCompute的数据，包括表（Table）和资源（Resource）等，会按照其数据容量的大小进行阶梯计费，计费周期为天。
-   以小时级别采集您每个项目空间下当前的存储使用情况，并以项目空间为基本单位，计算您当天的存储平均值再乘以单价。由于MaxCompute以项目空间为基本单位计算您当天的存储平均值。因此数据越集中存放在某个项目空间中，存储费用会越低。

假设您的某个项目的每天存储平均值为1 PB，原阶梯单价每天收取的费用如下。

```
(100-1)GB*0.0028 USD/GB/天 
+（1024-100）GB*0.0014 USD/GB/天 
+（10240-1024）GB*0.0013 USD/GB/天 
+（102400-10240）GB*0.0011 USD/GB/天 
+（10240*10240-102400）GB*0.0009 USD/GB/天
=966.486 USD/天
```

新阶梯单价每天收取费用如下：

```
(10240-1)GB*0.0011 USD/GB/天
+（102400-10240）GB*0.0009 USD/GB/天 
+（10240*10240-102400）GB*0.0006 USD/GB/天
=661.9125 USD/天
```

## 2020年2月24日-SQL兼容性升级

SQL兼容性升级时间预计如下，如有变更，请以实际通知时间为准。

|批次|站点|升级时间|
|--|--|----|
|第一批|印度尼西亚（雅加达） 、英国（伦敦）、印度（孟买）|2月24日|
|第二批|中东东部 1（迪拜）、美国东部 1（弗吉尼亚）、华北2政务云（北京）、中国香港（香港）|2月26日|
|第三批|马来西亚（吉隆坡）、日本（东京）、德国（法兰克福）|3月2日|
|第四批|美国西部1（硅谷）、亚太东南1（新加坡）、亚太东南2（悉尼）|3月4日|

-   [GET\_IDCARD\_AGE](/intl.zh-CN/开发/SQL及函数/内建函数/其他函数.md)函数行为变更：
    -   Get\_Idcard\_Age函数规则中”如果当前年份减去出生年份差值大于100则返回NULL“，升级为“返回年份减去出生年份差值”，即不存在大于100则返回NULL的情况。例如，`get_idcard_age('110101190001011009')`结果返回NULL，升级后结果为120。
    -   如果您希望升级后，该函数返回结果保留现状，则需要找出对应的查询，评估后进行改造。可以通过`get_idcard_age`结果加IF函数或者CASE WHEN表达式来解决。

        |原始查询|修改后查询|
        |----|-----|
        |GET\_IDCARD\_AGE\(idcardno\)|if\(GET\_IDCARD\_AGE\(idcardno\) \> 100, NULL, GET\_IDCARD\_AGE\(idcardno\)\)|
        |GET\_IDCARD\_AGE\(idcardno\)|CASE WHEN GET\_IDCARD\_AGE\(idcardno\) \> 100 THEN NULL ELSE GET\_IDCARD\_AGE\(idcardno\) END|

-   [CONCAT\_WS](/intl.zh-CN/开发/SQL及函数/内建函数/字符串函数.mdsection_xnf_sj1_wdb)函数行为变更：
    -   升级前，在查询运行时CONCAT\_WS函数没有打开Hive兼容并且有3个及以上参数，其中有一个参数是ARRAY类型时，参数中的`array item`不会出现在最终的结果中。例如，`concat_ws(',', array('a'), array('b', 'c'))`，期望结果为`"a,b,c"`，但是当前结果为`",,,"`。
    -   升级后，无需打开Hive兼容，CONCAT\_WS的参数支持STRING类型和ARRAY类型混合。`concat_ws(',', array('a'), array('b', 'c'))`的结果为`"a,b,c"`。
-   `Like%%`查询输入为空时返回值变更。

    [Like](/intl.zh-CN/开发/SQL及函数/附录/LIKE字符匹配.md)字符匹配函数，当它的输入是空字符串，而Pattern是`%%`时，当前返回为False；升级后，则返回True。

    ```
    --创建表，向表中插入空字符串。
    create table if not exists table_test (a string) lifecycle 3;
    insert into table table_test values ('');
    
    select a like '%%' from table_test;
    
    --当前返回如下。
    +------+
    | _c0  |
    +------+
    | false |
    +------+
    
    --升级后返回如下。
    +------+
    | _c0  |
    +------+
    | true |
    +------+
    ```


## 2019年12月25日-开源地理空间UDF

MaxCompute支持兼容ESRI专门为Apache Hive实现的开源地理空间UDF，您可以将此开源地理空间UDF注册到MaxCompute中，以兼容开源Hive UDF的方式实现地理空间函数使用，详情请参见[开源地理空间UDF](/intl.zh-CN/开发/SQL及函数/UDF/开源地理空间UDF.md)。

## 2019年10月11日-MaxCompute SQL新功能

-   JOIN与SETOP支持括号指定优先级

    ```
    SELECT * FROM src JOIN (src2 JOIN src3 on xxx) ON yyy; 
    SELECT * FROM src UNION ALL (SELECT * FROM src2 UNION ALL SELECT * FROM src3);
    ```

    详细内容请参见[JOIN](/intl.zh-CN/开发/SQL及函数/SELECT语句/JOIN.md)和[交集、并集和补集](/intl.zh-CN/开发/SQL及函数/SELECT语句/交集、并集和补集.md)。

-   支持hive.orderby.position.alias以及hive.groupby.position.alias

    当打开这两个Flag的时候，对应ORDER BY和GROUP BY中的整型常量被当做SELECT的列序号处理。

    ```
    表src的列为key和value
    SELECT * FROM src ORDER BY 1;
    --等同于
    SELECT * FROM src ORDER BY key;
    ```

    详细内容请参见[SELECT语法介绍](/intl.zh-CN/开发/SQL及函数/SELECT语句/SELECT语法介绍.md)。

-   新增内置函数
    -   新增内置函数`STRING JSON_TUPLE(STRING json,STRING key1,STRING key2,…)`：传入一组key和一个JSON字符串，返回一个元组。`JSON_TUPLE()` 支持包含中文的JSON数据解析，支持多层嵌套以及包含多重嵌套的数组的JSON数据解析。在需要对同一个JSON字符串多次解析的情况下，相比于多次调用get\_json\_object，json\_tuple可以一次输入多个key，且JSON字符串只被解析一次，效率更高。 详情请参见[字符串函数](/intl.zh-CN/开发/SQL及函数/内建函数/字符串函数.md)。
    -   新增内置函数`INT EXTRACT(datepart from timestamp)`：提取日期的一部分，datepart支持YEAR、MONTH、DAY等时间描述，timestamp 为Timestamp类型数据。 详细请参见[日期函数](/intl.zh-CN/开发/SQL及函数/内建函数/日期函数.md)。
-   支持指定表的列默认值

    DEFAULT VALUE允许您创建TABLE的时候指定默认值，INSERT的时候如果不指定该列，则插入默认值，举例如下。

    ```
    CREATE TABLE t (a bigint default 10, b bigint);
    INSERT INTO TABLE t(b) SELECT 100; 
    --等同于
    INSERT INTO TABLE t(a, b) SELECT 10, 100;
    ```

-   支持自然连接

    自然连接（Natural Join）即参与JOIN的两张表根据字段名字自动决定连接字段。支持`outer natural join`，支持使用`using`字段执行JOIN，输出字段中公共字段只出现一次，举例如下。

    ```
    --表src的列(key1, key2, a1, a2)，表src2的列(key1, key2, b1, b2)
    SELECT * FROM src NATURAL JOIN src2;
    --由于 src 和 src2 有两个同名字段 （key1, key2) ，所以上面的JOIN相当于：
    SELECT src.key1 as key1, src.key2 as key2, src.a1, src.a2, src2.b1, src2.b2 FROM src INNER JOIN src2 ON src.key1 = src2.key1 AND src.key2 = src2.key2;
    ```

    详细请参见[JOIN](/intl.zh-CN/开发/SQL及函数/SELECT语句/JOIN.md)。

-   支持LIMIT OFFSET

    OFFSET语句和ORDER BY LIMIT语句配合，可以指定跳过OFFSET数目的行。如下面的语句将`src`按照`key`从小到大排序后，输出第11到第20行 （OFFSET 10指定跳过前10行，LIMIT 10指定最多输出10行）。

    ```
    SELECT * FROM src ORDER BY key LIMIT 10 OFFSET 10；
    ```

    详细请参见[SELECT语法介绍](/intl.zh-CN/开发/SQL及函数/SELECT语句/SELECT语法介绍.md)。

-   其他内置语法结构

    -   支持IS DISTINCT FROM语法结构： `a is distinct from b` 相当于 `not(a <=> b)`，`a is not distinct from b` 相当于 `a <=> b`。
    -   支持字符串连接操作符（\|\|）： `a || b || c` 相当于 `concat(a, b, c)`。
    详细请参见[运算符](/intl.zh-CN/开发/SQL及函数/运算符.md)。

-   分区合并

    MaxCompute有分区数量上限6万的限制，当分区数量过多时，可使用合并分区功能，对数仓数据进行归档，降低分区数量。合并分区功能会将同一个表下多个分区数据快速合并成一个分区，并删除之前分区，把数据移动到指定的分区下。语法格式如下，详细内容请参见[分区和列操作](/intl.zh-CN/开发/SQL及函数/DDL语句/分区和列操作.md)。

    ```
    ALTER TABLE <tableName> MERGE [IF EXISTS] PARTITION(<predicate>) [, PARTITION(<predicate2>) ...] OVERWRITE PARTITION(<fullPartitionSpec>) ;
    ```

-   Add/Drop Partitions

    支持一次性增加或者删除多个分区，语法格式如下。

    ```
    ALTER TABLE t ADD [IF NOT EXISTS] PARTITION (p = '1') PARTITION (p = '2');
    ALTER TABLE t DROP [IF EXISTS]  PARTITION (p = '1'), PARTITION (p = '2');
    --注意ADD多个分区之间没有逗号，DROP的多个分区间有逗号。
    ```


## 2019年8月29日-外表自定义storagehandler实现Outputer接口升级

北京时间2019年8月29日，MaxCompute进行版本升级。期间，您在使用外表自定义storagehandler实现Outputer接口时，如果通过列名而非数字下标获取列数据，可能会引起作业失败。

升级时间：北京时间，2019年8月29日14:00~23:00

升级Region：美国西部1（硅谷）、亚太东南1（新加坡）

## 2019年8月21日-外表自定义storagehandler实现Outputer接口升级

北京时间2019年8月21日，MaxCompute进行版本升级。期间，您在使用外表自定义storagehandler实现Outputer接口时，如果通过列名而非数字下标获取列数据，可能会引起作业失败。

升级时间：北京时间，2019年8月21日14:00~23:00

升级Region：亚太东北1（东京）、欧洲中部1（法兰克福）、中国（香港）、亚太东南2（悉尼）

影响原因：`Outputer.output(Record record)`中，传入的record为Outputer的上一个Operator产生的记录，列名可能发生变化，系统无法保证固定列名。

例如，表达式`some_function(column_a)`产生的列名是一个临时列名。因此，使用`record.get(列名)`方式来获取列内容的用法都有可能受到影响，建议使用`record.get(index)方式`获取。Outputer里如需获取表的列名，请调用 `DataAttributes.getFullTableColumns()`。

如您遇到相关问题，请提交工单咨询。

## 2019年7月24日-MaxCompute Spark开放

开放Region：华东1、华北2、华南1、美西1、中国（香港）、德国、新加坡、印度。

## 2019年3月26日-SQL语言功能升级

-   支持Grouping Set多维聚合分析（Cube，Roll up），适配需要对a列做聚合，也要对b列做聚合，或者同时要按照a、b两列做聚合的场景。具体的使用方法请参见[GROUPING SETS](/intl.zh-CN/开发/SQL及函数/SELECT语句/GROUPING SETS.md)。
-   支持INTERSECT/MINUS/EXCEPT，具体使用方法请参见[交集、并集和补集](/intl.zh-CN/开发/SQL及函数/SELECT语句/交集、并集和补集.md)。
-   通过外表读取OSS上的ORC和Parquet格式的文件时，支持对文件的列裁剪，有效减少IO量，节省计算资源和成本。
-   Java UDX类型系统增强：UDF支持Writable参数，具体使用方法请参见[Java UDF](/intl.zh-CN/开发/SQL及函数/UDF/Java UDF.md)。

**SQL性能优化**

-   DynamicDAG：动态优化的必要机制，它可以将一个优化（可能是资源配置或算法选择）延迟到运行时，以便提高优化的精准度，降低产生较差计划的可能性。
-   ShuffleRemove Optimization：针对Shuffle的优化。 从本次版本升级开始，MaxCompute将支持对inner join时右表key相同的场景进行Shuffle Remove优化。

## 2019年3月1日-MaxCompute 外部表开始收费

从2019年3月1日开始，MaxCompute SQL外部表（处理OSS/Table Store数据）功能开始计费。

计费标准为：

```
一次SQL计算费用=计算输入数据量*SQL价格
```

SQL价格为0.0044 USD/GB。当天的所有计量信息在第二天做一次性汇总收费，并直接体现在您的账户账单中。详情请参见[计费方式](/intl.zh-CN/产品定价/计费方式.md)。如有疑问，您可提交工单咨询。

## 2019年1月15日16:00~20:00-中国（香港）Region底层优化

为向您提供更好的产品性能和稳定性，MaxCompute将于北京时间2019年1月15日16:00~20:00对中国（香港）Region底层元数据仓库组件进行优化。在优化期间，中国（香港）Region用户的应用可能出现1分钟左右任务无法提交、运行中任务失败的情况。极端情况下，应用不可用时间将延长至30分钟。请您尽量避免在迁移窗口提交作业。其他Region不受影响。如果您有任何问题，可随时通过企业钉钉群或工单反馈。

## 2018年12月24日-MaxCompute支持时区配置

MaxCompute Project时区默认是中国的东八区，在用到DATETIME、TIMESTAMP或DATE类型相关的字段以及相关时间内置函数都是按东八区进行计算，2018年12月24日MaxCompute开始支持时区配置，有以下两种方式：

-   Session级别： `set odps.sql.timezone=<timezoneid>;`，该语句需要与计算语句一起提交。

    ```
    set odps.sql.timezone=Asia/Tokyo;
    select getdate();
    --结果如下。
    output:
    +------------+
    | _c0        |
    +------------+
    | 2018-10-30 23:49:50 |
    +------------+
    ```

-   Project级别： `setProject odps.sql.timezone=<timezoneid>;`，该语句需要Project Owner执行。执行此命令后该Project下相关的时间计算就会取设置后的时区，因此对于原有的任务数据会有影响，所以该操作需谨慎。建议仅对新增Project进行设置，对已有数据的Project不设置。

使用限制及注意事项：

-   时区配置支持范围为：SQL内置日期函数、UDF、UDT、UDJ、`select transform`都支持获取Project Timezone属性来支持时区。
-   时区支持的格式为`Asia/Shanghai`（存在夏令时跳变），不支持GMT+9格式。
-   当SDK时区与Project时区不同时，DATETIME类型转化为STRING类型操作需设置GMT时区。
-   时区配置后，通过DataWorks执行相关SQL时，日期显示某些时间段会有时间差异。例如，1900~1928年的日期时间差异5分52秒，1900年之前的日期时间差异9秒。
-   为了保证MaxCompute在多个时区DATETIME类型数据的正确性，MaxCompute服务、Java SDK以及配套的客户端将在近期进行版本更新（`-oversea`后缀的Java SDK、客户端版本），更新后可能影响MaxCompute中已经存储的早于1928年的DATETIME类型数据的显示。
-   建议（非中国东八区的Region）同步更新Java SDK、客户端版本，以便保证SQL计算结果及Tunnel传输数据在1900-01-01之后范围的准确性和一致性。而对于早于1900-01-01的DATETIME数据，SQL的计算显示结果和Tunnel传输数据仍旧可能存在343秒的差异。对于新版本SDK、客户端之前已经上传的早于1928-01-01的DateTime数据，在新版本中会减少352秒。
-   如果继续沿用不带有`-oversea`后缀的SDK、客户端，将存在SQL计算结果和Tunnel传输数据存在差异的风险。例如，早于1900-01-01的数据差异为9秒，1900-01-01~1928-01-01的数据差异为352秒。

    **说明：** Java SDK、客户端版本更新配置时区不影响DataWorks的时区配置，因此时区会存在差异，需要您对DataWorks中定时任务调度的影响进行计算评估。在日本Region，DataWorks服务器是GMT+9时区，在新加坡Region，DataWorks服务器是GMT+8时区。

-   通过JDBC连接的第三方客户端需要在客户端设置时区，保证与服务端时区设置一致性。
-   MapReduce支持时区功能。
-   Spark支持时区功能。
    -   对于提交到MaxCompute计算集群的任务形式，可以自动获取Project时区。
    -   通过yarn-client模式启动（例如spark-shell，spark-sql，pyspark等）的设置，需要您手动配置Driver的启动参数（spark-defaults.conf），增加`spark.driver.extraJavaOptions -Duser.timezone=America/Los_Angeles`，Timezone是要使用的时区。
-   PAI支持时区功能。
-   Graph支持时区功能。

